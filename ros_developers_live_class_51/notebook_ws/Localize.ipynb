{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logos/TClogo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in colaboration with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/robotnik.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### presents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS Developers Live Class n51\n",
    "\n",
    "# How to fuse odometry & IMU with *robot_localization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is additional material for the **ROS Developers Live Class n.51** created and provided for free by **Alberto Ezquerro** and **Ricardo Tellez** of <a href=\"www.theconstructsim.com\">The Construct</a>. You can distribute this notebook as long as you provide copy of this paragraph with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's live class, we are going to learn the following contents:\n",
    "1. Why it is needed to fuse sensor data for navigation\n",
    "2. What is the *robot_localization* package\n",
    "3. How to use the *robot_localization* package for sensor fusion\n",
    "\n",
    "Pre-requisites for this live class are:\n",
    "* Basic knowledge of ROS concepts such as topics, publish and subscribe, ROS Service\n",
    "* Know how to create a map and how to localize a robot in it. <a href=\"https://youtu.be/RknTTpga64s\">Check Live Class n49 if you don't know how</a>\n",
    "* Love for Robotics \n",
    "* ...that's it!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summit XL robot by Robotnik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Summitxl_sim2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this class we are going to use the Summit XL robot by <a href=\"\">Robotnik</a>. That is a robot that has the following characteristics:\n",
    "\n",
    "* Four wheels\n",
    "* Laser ranger\n",
    "* IMU\n",
    "* Camera\n",
    "* GPS\n",
    "\n",
    "In case you are interested on this robot, you can <a href=\"https://www.robotnik.eu/mobile-robots/summit-xl/\">find more information here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Summitxl_real.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use this ROSject\n",
    "\n",
    "A <a href=\"http://rosjects.com\">**ROSject**</a> is a **ROS project** packaged in such a way that all the material it contains (**ROS code, Gazebo simulations and Notebooks**) can be shared with any body **using only a web link**. That is what we did with all the attendants to the Live Class, we shared this ROSject with them (so they can have access to all the ROS material they contain).\n",
    "\n",
    "**Check <a heref=\"https://www.youtube.com/watch?v=cR-Ow5K7oSo\">this webinar</a> to learn more about ROSjects and how to create your own ROSjects**.\n",
    "\n",
    "You will need to have a free account at the <a href=\"http://rosds.online\">ROS Development Studio</a> (ROSDS). Get the account and then follow the indications below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why do we need to fuse sensor data for autonomous robot navigation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because sensor data is noisy, which produces an error in the localization of the robot.\n",
    "\n",
    "When talking about odometry, the better the odometry, the better the localization of the robot.\n",
    "\n",
    "The problem with errors in odometry is that they accummulate over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/comparison.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is the *robot_localization* package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a package for mixing different sources of odometry into a more stable one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/robot_localization_graph1.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Let's launch Summit XL simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that you need to go to **Simulations->Summit XL**. After that you should get the following simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Summitxl_sim1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's launch the code that adds noise to odometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check in Rviz how the odometry looks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch the Rviz to localize the robot in the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ rosrun rviz rviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the config file for Rviz that is provided in this rosject at */home/user/odom_config.rviz*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch the noisy_odom package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ rosrun noisy_odom add_noise.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/odom1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Let's configure the *robot_localization* package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new ROS package that we are going to call **summit_odometry**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ cd ~/catkin_ws/src\n",
    "$ catkin_create_pkg summit_odometry\n",
    "$ cd summit_odometry\n",
    "$ mkdir launch\n",
    "$ mkdir config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a launch file named *start_filter.launch* with the following content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<launch> \n",
    "\n",
    "    <!-- Run the EKF Localization node -->\n",
    "    <node pkg=\"robot_localization\" type=\"ekf_localization_node\" name=\"ekf_localization\">\n",
    "        <rosparam command=\"load\" file=\"$(find summit_odometry)/config/ekf_localization.yaml\"/>\n",
    "    </node>\n",
    "\n",
    "</launch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, what we are doing here is to launch the ROS program named **ekf_localization_node** (which uses the Extended Kalman Filter), from the **robot_localization** package with a specific configuration file named **ekf_localization.yaml**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, inside this folder, create the configuration file, named **ekf_localization.yaml**. Inside this file, you will place the following configuration. Complete all the parameters that are with an interrogation sign (?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Configuation for robot odometry EKF\n",
    "#\n",
    "frequency: 50\n",
    "    \n",
    "two_d_mode: true\n",
    "    \n",
    "publish_tf: false\n",
    "\n",
    "# Complete the frames section \n",
    "odom_frame: ?\n",
    "base_link_frame: ?\n",
    "world_frame: ?\n",
    "map_frame: ?\n",
    "\n",
    "# Complete the odom0 configuration\n",
    "odom0: ?\n",
    "odom0_config: [?, ?, ?,\n",
    "               ?, ?, ?,\n",
    "               ?, ?, ?,\n",
    "               ?, ?, ?,\n",
    "               ?, ?, ?,]\n",
    "odom0_differential: false\n",
    "\n",
    "# Complete the imu0 configuration\n",
    "imu0: ?\n",
    "imu0_config: [?, ?, ?,\n",
    "              ?, ?, ?,\n",
    "              ?, ?, ?,\n",
    "              ?, ?, ?,\n",
    "              ?, ?, ?,]\n",
    "imu0_differential: false\n",
    "\n",
    "process_noise_covariance\": [0.05, 0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0.05, 0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0.06, 0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0.03, 0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0.03, 0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0.06, 0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0.025, 0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0,     0.025, 0,    0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0,     0,     0.04, 0,    0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0,     0,     0,    0.01, 0,    0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0.01, 0,    0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0.02, 0,    0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0.01, 0,    0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0.01, 0,\n",
    "                                              0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0.015]\n",
    "\n",
    "\n",
    "initial_estimate_covariance: [1e-9, 0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    1e-9, 0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    1e-9, 0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    1e-9, 0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    1e-9, 0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    1e-9, 0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    1e-9, 0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    0,    1e-9, 0,    0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    0,    0,    1e-9, 0,     0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    0,    0,    0,    1e-9,  0,     0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     1e-9,  0,     0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     1e-9,  0,    0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     1e-9, 0,    0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    1e-9, 0,\n",
    "                                                      0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    1e-9]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The reference frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **base_link_frame**: It is the frame that is in the robot itself, to which any sensor can be referenced. It is usually located in the center of the robot. It travels with it.\n",
    "\n",
    "\n",
    "* **odom_frame**: It is the frame that is used to report the odometry.\n",
    "\n",
    "\n",
    "* **map_frame**: It is the frame that is used to report a global position from a system that knows where the robot is. For instance an AMCL system. If you are not using any external Localization system, the this can be ignored.\n",
    "\n",
    "\n",
    "* **world_frame**: It is the frame that references which one of the two previous frames is going to be used to get the absolute coordinates of the robot in the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case that would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_link_frame: base_link\n",
    "odom_frame: odom\n",
    "world_frame: odom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding sensors to fuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any sensor that produces messages in any of these formats, can be fed to the robot_localization package to estimate the robot position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <a href=\"http://docs.ros.org/melodic/api/nav_msgs/html/msg/Odometry.html\" target=\"_blank\">nav_msgs/Odometry</a>\n",
    "\n",
    "* <a href=\"http://docs.ros.org/melodic/api/nav_msgs/html/msg/Odometry.html\" target=\"_blank\">sensor_msgs/Imu</a>\n",
    "\n",
    "* <a href=\"http://docs.ros.org/lunar/api/geometry_msgs/html/msg/PoseWithCovarianceStamped.html\" target=\"_blank\">geometry_msgs/PoseWithCovarianceStamped</a>\n",
    "\n",
    "* <a href=\"http://docs.ros.org/melodic/api/geometry_msgs/html/msg/TwistWithCovarianceStamped.html\" target=\"_blank\">geometry_msgs/TwistWithCovarianceStamped</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, most importantly, you can have many of each sensor. This means that, for instance, you can have the odometry provided by two different sensors (wheel encoders and visual odometry), or two different Inertial Measurement Units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. First indicate the topic of the sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case are:\n",
    "\n",
    "* /noisy_odom\n",
    "* /imu/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Configure the variables matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, from each of the input sensors, we must specify which components of their messages are going to be merged (fused) in the Kalman Filter to compute the final state estimation. To specify this, you must fill a 3x5 value matrix. The matrix means the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[  X,        Y,       Z\n",
    "  roll,    pitch,    yaw\n",
    "  X/dt,     Y/dt,    Z/dt\n",
    " roll/dt, pitch/dt, yaw/dt\n",
    "  X/dt2,    Y/dt2,   Z/dt2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above values mean the following:\n",
    "\n",
    "* **X, Y, Z**: These are the [x,y,z] coordinates of the robot.\n",
    "* **roll, pitch, yaw**: These are the rpy axis, which specify the orientation of the robot.\n",
    "* **X/dt, Y/dt, Z/dt**: These are the velocities of the robot.\n",
    "* **roll/dt, pitch/dt, yaw/dt**: These are the angular velocities of the robot\n",
    "* **X/$dt^2$, Y/$dt^2$, Z/$dt^2$**: These are the linear accelerations of the robot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in this case, the values we are taking into account for the Kalman Filter are, for the odometry data:\n",
    "\n",
    "* linear velocities in X and Y, and angular velocity in Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odom0_config: [false, false, false\n",
    " false, false, false\n",
    " true,  true,  false\n",
    " false, false, true\n",
    " false, false, false,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the IMU data:\n",
    "\n",
    "* yaw(orientation), angular velocity in Z and linear acceleration in X. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Covariance matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **process_noise_covariance**: This parameter is used to model uncertainty in the prediction stage of the filtering algorithms. WHAT!!?? Basically, it's used to improve the results produced by the filter. The values on the diagonals are the variances for the state vector, which include pose, then velocities, then linear acceleration. It is not mandatory to set, but you will achieve superior results by tunning it. Anyways, unless you are an expert on the matter, it's not easy to set at all. So, the best option in that case would be to test different values, and see how they improve or decrease the results.\n",
    "\n",
    "\n",
    "* **initial_state_covariance**: The estimate covariance defines the error in the current state estimate. This parameter allows to set the initial value for the matrix, which will affect how quickly the filter converges.\n",
    "Here's the rule you should follow: if you are measuring a variable, make the diagonal value in initial_estimate_covariance larger than that measurement's covariance. So, for example, if your measurement's covariace value for the variable in question is 1e-6, make the initial_estimate_covariance diagonal value 1e-3 or something like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Launch the *robot_localization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to launch the *robot_localization* with your configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ roslaunch summit_odometry start_filter.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check now in Rviz that the odometry is now filtered and stabilized. You can find the result in topic:\n",
    "\n",
    "*/odom/filtered*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. How to connect to the real robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT: kill the simulation window to prevent interferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Husarnet communication package in the robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First you need to install a package in the robot itself which allows IP6 communication with ROSDS. This is possible thanks to Husarnet.\n",
    "\n",
    "The package has been already installed in the robot by our team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Start the communication script in the robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to start the *set_etc_hosts_mode.py* script to put the robot in communication mode.\n",
    "\n",
    "This has been already done by our team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ sudo python set_etc_hosts_mode.py RemoteMode summit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in time, you should ask the robot for its communication address by issuing the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ sudo husarnet websetup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also get the hostname of the computer of the robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start the robot network in ROSDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the top menu and select **Real Robot->Robot Network**.\n",
    "\n",
    "After a few seconds you should see that you have started the robot network of ROSDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/robot_network.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Add a connection to a robot in ROSDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add a new connection to a robot by using the top menu and select **Real Robot->Add device**.\n",
    "\n",
    "On the dialog that will appear, indicate the **hostname** of the robot's computer, and the **communication web address** that you got on step 1.\n",
    "\n",
    "After a few seconds you should see the following configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/robot_network.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Set the master to the summit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to indicate to ROSDS that the ROS_MASTER_URI should be pointing to the robot and not to the ROSDS itself.\n",
    "\n",
    "For that, \n",
    "\n",
    "* first, we recommend to kill the simulation to prevent conflic with the topics of the real robot. \n",
    "\n",
    "* Then, go to **Real Robot** and click on the circle of the **summit**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From this point, the ROSDS is connected to the real robot!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the topics in a shell correspond to the ones in the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ rostopic list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Re-launch the *robot_localization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ roslaunch summit_odometry start_filter.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Check in rviz the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ rosrun rviz rviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mission completed!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you log off, remember to <span style=\"background: #098be8; padding: 10px; color:white;\">GIVE US A LIKE</span> and hit the <span style=\"background: #098be8; padding: 10px; color:white;\">THUMBS UP</span> and <span style=\"background: #098be8; padding: 10px; color:white;\">SUBSCRIBE</span> for more weekly tutorials!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an online academy that teaches you more about how to make robots navigate with ROS using GPS or laser sensors, as well as all the details of all the parameters of the configuration. Check the following related courses:\n",
    "* <a href=\"http://www.theconstructsim.com/construct-learn-develop-robots-using-ros/robotigniteacademy_learnros/ros-courses-library/ros-robot-localization-package/\">Fuse sensor data to improve localization</a>\n",
    "* <a href=\"https://goo.gl/iog3x9\">Mastering with ROS: Summit XL robot</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a href=\"https://goo.gl/7ApVAp\"><img src=\"images/logos/RIAlogo.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rosdevcon2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **hands on conference** where you will **learn and practice** at the same time **with the speakers**. \n",
    "\n",
    "It is an online conference with the same format of the Live Classes. You can attend from anywhere and will get a **rosject** with all the content of the speakers.\n",
    "\n",
    "#### 8 speakers - 8 practical ROS projects on a single weekend\n",
    "\n",
    "### You can also be a speaker of the conference. Check the call for papers\n",
    "\n",
    "### More information here: <a href=\"http://www.rosdevcon.com\">www.rosdevcon.com</a>\n",
    "\n",
    "### Check the videos of the previous ROSDevCon 2018 <a href=\"\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# KEEP PUSHING YOUR ROS LEARNING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
